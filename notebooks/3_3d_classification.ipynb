{"cells":[{"cell_type":"markdown","metadata":{"id":"KNHyoaF_gRJW"},"source":["# set path"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15612,"status":"ok","timestamp":1718983083748,"user":{"displayName":"Sergei Bykov","userId":"01890788171986104640"},"user_tz":-120},"id":"GVQcslAjgRJX","outputId":"ac0ebe76-175e-4dad-b31d-bc3578b2c3a4"},"outputs":[],"source":["import os\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive/', force_remount=False)\n","\n","    #unpack zipped file (reading files from drive is slow)\n","    os.chdir('/content')\n","    import shutil\n","    print(\"Unzipping data...\")\n","    shutil.unpack_archive(\"/content/drive/My Drive/ai-side-projects/self-supervised-halos/data/freya_postprocess.zip\", \"./\")\n","    print(\"Unzipping done\")\n","    rootpath = '/content/freya_postprocess/'\n","\n","except:\n","    %matplotlib inline\n","    rootpath = '/Users/sdbykov/work/self-supervised-halos/data/freya_postprocess/'\n"]},{"cell_type":"markdown","metadata":{"id":"eiGU2gOQgRJY"},"source":["# Imports"]},{"cell_type":"code","execution_count":101,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1718983083748,"user":{"displayName":"Sergei Bykov","userId":"01890788171986104640"},"user_tz":-120},"id":"4oczIy3cgRJY"},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":102,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1718983083748,"user":{"displayName":"Sergei Bykov","userId":"01890788171986104640"},"user_tz":-120},"id":"WVcLwdbKgRJY"},"outputs":[],"source":["import torchvision"]},{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4201,"status":"ok","timestamp":1718983087948,"user":{"displayName":"Sergei Bykov","userId":"01890788171986104640"},"user_tz":-120},"id":"9ucft9BsgRJY","outputId":"0fc708df-df17-43e6-fb60-5189829fbf2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from glob import glob\n","from tqdm import tqdm\n","import time\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.transforms.functional as TF\n","\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","\n","try:\n","    subhalos_df = pd.read_pickle('/content/drive/My Drive/ai-side-projects/self-supervised-halos/data/subhalos_df.pkl')\n","except:\n","    subhalos_df = pd.read_pickle('/Users/sdbykov/work/self-supervised-halos/data/subhalos_df.pkl')\n","subhalos_df['logSubhaloMass'] = np.log10(subhalos_df['SubhaloMass']*1e10/0.6774)\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)\n","if device=='cuda':\n","    print(torch.cuda.get_device_properties(0).name)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ploWAJLngRJY"},"source":["# Data loaders and transformers"]},{"cell_type":"code","execution_count":104,"metadata":{"executionInfo":{"elapsed":12999,"status":"ok","timestamp":1718983100945,"user":{"displayName":"Sergei Bykov","userId":"01890788171986104640"},"user_tz":-120},"id":"yys9KXVFgRJZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["bin weights: [4.08623003e-04 8.36488906e-04 1.83216523e-03 3.89963599e-03\n"," 8.45849615e-03 1.80333421e-02 4.49692201e-02 9.10914971e-02\n"," 3.22960762e-01 5.07509769e-01], bin counts: [8694 4247 1939  911  420  197   79   39   11    7], bins: [11.   11.37 11.74 12.11 12.48 12.85 13.22 13.59 13.96 14.33 14.7 ]\n"]}],"source":["mass_bins = np.linspace(11, 14.7, 11) ## number of classes = len(mass_bins) - 1 = 10\n","mass_bins_nums = np.histogram(subhalos_df['logSubhaloMass'], bins=mass_bins)[0]\n","#mass_bins_nums = np.log10(mass_bins_nums+1) #logarithm to make the difference between bins less pronounced\n","mass_bins_weights = np.max(mass_bins_nums)/mass_bins_nums\n","mass_bins_weights = mass_bins_weights / np.sum(mass_bins_weights)\n","\n","print(f\"bin weights: {mass_bins_weights}, bin counts: {mass_bins_nums}, bins: {mass_bins}\")\n","#i think log is better weight, with linear weighting, low mass halos almost do not contribute to the loss due to small weight relative to normal halos (large mass bin is 0.1-0.5, and smallest is 4e-4).\n","mass_bins_weights = torch.tensor(mass_bins_weights, dtype=torch.float32)\n","\n","\n","class HaloDataset(torch.utils.data.Dataset):\n","    mass_bins = np.linspace(11, 14.7, 11)  # Define mass_bins globally or pass as argument\n","\n","    def __init__(self, root_dir, subhalos_df,\n","                 load_2d=True, load_3d=False, load_mass=False,\n","                 DEBUG_LIMIT_FILES=None):\n","        self.root_dir = root_dir\n","        self.subhalos_df = subhalos_df\n","        self.files_3d = sorted(glob(root_dir +  '3d/*.npz'))\n","        self.files_2d = sorted(glob(root_dir + '2d/*.npz'))\n","        self.files_mass = sorted(glob(root_dir + 'mass/*.npz'))\n","\n","        if DEBUG_LIMIT_FILES:\n","            self.files_3d = self.files_3d[:DEBUG_LIMIT_FILES]\n","            self.files_2d = self.files_2d[:DEBUG_LIMIT_FILES]\n","            self.files_mass = self.files_mass[:DEBUG_LIMIT_FILES]\n","\n","        self.load_2d = load_2d\n","        self.load_3d = load_3d\n","        self.load_mass = load_mass\n","\n","\n","        self.halos_ids = [int(file.split('_')[-2].split('.')[0]) for file in self.files_2d]\n","        self.loaded_data = self.preload_data()\n","\n","\n","    def preload_data(self):\n","        #lesson learned: loading all data at once is faster than loading it on the fly. Before that all files were loaded for each index separately and with the inference time of 0.1 sec the data loading was 30 sec\n","        load_2d = self.load_2d\n","        load_3d = self.load_3d\n","        load_mass = self.load_mass\n","\n","        data_dict = {}\n","\n","\n","        data_dict_3d = {}\n","        data_dict_mass = {}\n","\n","        if load_2d:\n","            data_dict_2d = {}\n","            for file in tqdm(self.files_2d, desc='Preparing 2D data'):\n","                halo_id = int(file.split('_')[-2].split('.')[0])\n","                data = np.load(file)\n","                data_dict_2d[halo_id] = {\n","                    'map_2d_xy': data['map_2d_xy'],\n","                    'map_2d_xz': data['map_2d_xz'],\n","                    'map_2d_yz': data['map_2d_yz'],\n","                }\n","            data_dict['2d'] = data_dict_2d\n","        \n","        if load_3d:\n","            for file in tqdm(self.files_3d, desc='Preparing 3D data'):\n","                halo_id = int(file.split('_')[-2].split('.')[0])\n","                data = np.load(file)\n","                data_dict_3d[halo_id] = {\n","                    'map_3d': data['map_3d'],\n","                }\n","            data_dict['3d'] = data_dict_3d\n","        \n","        if load_mass:\n","            for file in tqdm(self.files_mass, desc='Preparing mass data'):\n","                halo_id = int(file.split('_')[-2].split('.')[0])\n","                data = np.load(file)\n","                data_dict_mass[halo_id] = {\n","                    'mass_hist': data['mass_hist'],\n","                    'snap': data['snap'],\n","                }\n","            data_dict['mass'] = data_dict_mass\n","\n","        return data_dict\n","\n","    def __len__(self):\n","        return len(self.halos_ids)\n","\n","    def select_random_projection(self):\n","        return np.random.choice(['xy', 'xz', 'yz'])\n","\n","\n","    def __getitem_2d__(self, idx):\n","        if not self.load_2d:\n","            return np.zeros(1)\n","\n","        halo_id = self.halos_ids[idx]\n","        data_2d = self.loaded_data['2d'][halo_id]\n","\n","        # Select a random projection\n","        selected_projection = self.select_random_projection()\n","\n","        if selected_projection == 'xy':\n","            selected_data = np.expand_dims(data_2d['map_2d_xy'], axis=0)\n","        elif selected_projection == 'xz':\n","            selected_data = np.expand_dims(data_2d['map_2d_xz'], axis=0)\n","        elif selected_projection == 'yz':\n","            selected_data = np.expand_dims(data_2d['map_2d_yz'], axis=0)\n","\n","        return selected_data\n","    \n","    def __getitem_3d__(self, idx):\n","        if not self.load_3d:\n","            return np.zeros(1)\n","        halo_id = self.halos_ids[idx]\n","        data_3d = self.loaded_data['3d'][halo_id]\n","        selected_data = np.expand_dims(data_3d['map_3d'], axis=0)\n","        return selected_data\n","    \n","    def __getitem_mass__(self, idx):\n","        if not self.load_mass:\n","            return (np.zeros(1), np.zeros(1))\n","\n","        halo_id = self.halos_ids[idx]\n","        data_mass = self.loaded_data['mass'][halo_id]\n","        snap = data_mass['snap']\n","        mass_hist = data_mass['mass_hist']\n","        selected_data = (snap, mass_hist)\n","        selected_data = np.expand_dims(selected_data, axis=0)\n","\n","        return selected_data\n","    \n","    def __getitem_label__(self, idx):\n","        halo_id = self.halos_ids[idx]\n","        label_mass = self.subhalos_df.loc[halo_id]['logSubhaloMass']\n","        label_class = np.digitize(label_mass, self.mass_bins) - 1\n","        label = (label_mass, label_class, halo_id)\n","        return label\n","\n","\n","    def __getitem__(self, idx):\n","\n","        data_2d = self.__getitem_2d__(idx)\n","        \n","        data_3d = self.__getitem_3d__(idx)\n","        \n","        data_mass = self.__getitem_mass__(idx)\n","        \n","        label = self.__getitem_label__(idx)\n","\n","        result_tuple = (data_2d, data_3d, data_mass)\n","\n","        return result_tuple, label\n","\n","\n","##full dataset\n","#dataset = HaloDataset(root_dir = rootpath, subhalos_df=subhalos_df, load_2d=True, load_3d=True, load_mass=True)\n","#dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Preparing 3D data: 100%|██████████| 16544/16544 [01:20<00:00, 204.37it/s]\n","Preparing mass data: 100%|██████████| 16544/16544 [00:27<00:00, 605.38it/s]\n"]}],"source":["dataset = HaloDataset(root_dir = rootpath, subhalos_df=subhalos_df, load_2d=False, load_3d=True, load_mass=True)\n","dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 130/130 [00:27<00:00,  4.74it/s]\n"]}],"source":["for data, label in tqdm(dataloader):\n","    pass"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":0}
