{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available.\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "from self_supervised_halos.utils.utils import data_preprocess_path, check_cuda\n",
    "from scripts.classification_3d import ClassificationModel, report_classification_performance\n",
    "\n",
    "from self_supervised_halos.utils.dataloader import HaloDataset, img3d_transform, subhalos_df, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = check_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HaloDataset(root_dir=data_preprocess_path,subhalos_df=subhalos_df, \n",
    "                      load_2d=False, load_3d=True, load_mass=False,\n",
    "                        choose_two_2d = False,\n",
    "                      DEBUG_LIMIT_FILES = None)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 128\n"
     ]
    }
   ],
   "source": [
    "if device=='cpu':\n",
    "    batch_size = 128\n",
    "else:\n",
    "    print('dataloader on gpu')\n",
    "    batch_size = 512\n",
    "\n",
    "print(f'Batch size: {batch_size}')\n",
    "\n",
    "n_data = len(dataset)\n",
    "f_train = 0.6\n",
    "f_val = 0.2\n",
    "f_test = 1 - f_train - f_val\n",
    "\n",
    "\n",
    "train_size = int(f_train*len(dataset))\n",
    "val_size = int(f_val*len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "\n",
    "trainval_ds, test_ds = torch.utils.data.random_split(dataset, [train_size+val_size, test_size])\n",
    "train_size = int(f_train/(f_train+f_val)*len(trainval_ds))\n",
    "val_size = len(trainval_ds) - train_size\n",
    "\n",
    "train_ds, val_ds = torch.utils.data.random_split(trainval_ds, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Classification_3d not found at /Users/sdbykov/work/self_supervised_halos//results/models/Classification_3d.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial Forward Pass: 100%|██████████| 78/78 [00:44<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial forward pass elapsed time: 44.16 s (limit_to_first_batch=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 5e-3\n",
    "n_epochs=5\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=dataset.mass_bins_weights.to(device)).to(device)\n",
    "\n",
    "model = ClassificationModel(\n",
    "                    optimizer_class=torch.optim.Adam,\n",
    "                    optimizer_params={'lr':lr},\n",
    "                    scheduler_class=torch.optim.lr_scheduler.StepLR,\n",
    "                    scheduler_params={'step_size':15, 'gamma':0.5},\n",
    "                    criterion=criterion,\n",
    "                    history=None,\n",
    "                    transform=None, #TODO add 3d transform\n",
    ")\n",
    "\n",
    "model.load('Classification_3d.pth')\n",
    "\n",
    "model.trial_forward_pass(train_loader, device, limit_to_first_batch=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training_loop(\n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader,\n",
    "    num_epochs=n_epochs, \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(model.history['train_loss'], label='train')\n",
    "plt.plot(model.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.show_transforms(train_loader, device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = report_classification_performance(model, val_loader, \n",
    "device=device)\n",
    "report_classification_performance(model, val_loader, device=device, viz_one = True)\n",
    "\n",
    "pd.crosstab(result_df['true_class'], result_df['pred_class'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openTSNE import TSNE #!conda install --channel conda-forge opentsne -y\n",
    "from tqdm import tqdm \n",
    "\n",
    "def gather_cnn_features(model, loader, device, transform = None):\n",
    "    model.model.eval()\n",
    "    cnn = model.model.cnn\n",
    "    features = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in tqdm(enumerate(loader), total=len(loader)):\n",
    "            data, label = batch\n",
    "            img = data[0]\n",
    "            label = label[1]\n",
    "\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            if transform is not None:\n",
    "                img = transform(img)\n",
    "\n",
    "\n",
    "            output = cnn(img).cpu().numpy()\n",
    "            \n",
    "            features.append(output)\n",
    "            labels.append(label.cpu().numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "features, labels = gather_cnn_features(model, train_loader, device, transform = img2d_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(\n",
    "    n_components = 2,\n",
    "    perplexity=30,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "features_embedding = tsne.fit(features) \n",
    "#timing\n",
    "#approx 3m30s min for first 1000 example of 78 batches of train dataloader (approx 1000 out of 9000 halos)\n",
    "#approx 3m30s min for first all examples of 78 batches of train dataloader (approx 9000 halos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_labels = len(features_embedding)\n",
    "\n",
    "fig, axs = plt.subplots(4, (len(np.unique(labels))+1)//4+1, figsize = (15,15))\n",
    "axs=axs.flatten()\n",
    "\n",
    "\n",
    "axs[0].scatter(features_embedding[:limit_labels, 0], features_embedding[:limit_labels, 1], c = 'k', s = 1)\n",
    "\n",
    "for i,label in enumerate(np.unique(labels)):\n",
    "    mask = labels[:limit_labels]==label\n",
    "    axs[i+1].scatter(features_embedding[:limit_labels, 0][mask], features_embedding[:limit_labels, 1][mask], s = 30, alpha = 0.4)\n",
    "\n",
    "    axs[i+1].set_title(label)\n",
    "\n",
    "axs[0].set_title('all')\n",
    "\n",
    "axs[i+1].set_xlabel('tsne1')\n",
    "axs[0].set_ylabel('tsne2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for label in np.unique(labels):\n",
    "    idx = labels[:1000] == label\n",
    "    plt.scatter(features_embedding[idx, 0], features_embedding[idx, 1], label=str(label), s=30, alpha = 0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_embedding[:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hea",
   "language": "python",
   "name": "venv_hea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
